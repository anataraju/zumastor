diff --git a/block/ll_rw_blk.c b/block/ll_rw_blk.c
index 8b91994..b2b7e42 100644
--- a/block/ll_rw_blk.c
+++ b/block/ll_rw_blk.c
@@ -3210,9 +3210,9 @@ static inline int bio_check_eod(struct bio *bio, unsigned int nr_sectors)
  */
 static inline void __generic_make_request(struct bio *bio)
 {
-	struct request_queue *q;
+	struct request_queue *q = bdev_get_queue(bio->bi_bdev);
 	sector_t old_sector;
-	int ret, nr_sectors = bio_sectors(bio);
+	int nr_sectors = bio_sectors(bio);
 	dev_t old_dev;
 	int err = -EIO;
 
@@ -3221,6 +3221,13 @@ static inline void __generic_make_request(struct bio *bio)
 	if (bio_check_eod(bio, nr_sectors))
 		goto end_io;
 
+	if (q && q->metric && !bio->bi_queue) {
+		int need = bio->bi_max_vecs;
+		bio->bi_queue = q;
+		/* FIXME: potential race if atomic_sub is called in the middle of condition check */
+		wait_event(q->throttle_wait, atomic_read(&q->available) >= need);
+		atomic_sub(need, &q->available);
+	}
 	/*
 	 * Resolve the mapping until finished. (drivers are
 	 * still free to implement/resolve their own stacking
@@ -3231,10 +3238,9 @@ static inline void __generic_make_request(struct bio *bio)
 	 */
 	old_sector = -1;
 	old_dev = 0;
-	do {
+	while (1) {
 		char b[BDEVNAME_SIZE];
 
-		q = bdev_get_queue(bio->bi_bdev);
 		if (!q) {
 			printk(KERN_ERR
 			       "generic_make_request: Trying to access "
@@ -3282,8 +3288,10 @@ end_io:
 			goto end_io;
 		}
 
-		ret = q->make_request_fn(q, bio);
-	} while (ret);
+		if (!q->make_request_fn(q, bio))
+			return;
+		q = bdev_get_queue(bio->bi_bdev);
+	}
 }
 
 /*
diff --git a/drivers/md/dm.c b/drivers/md/dm.c
index 88c0fd6..45dc7b0 100644
--- a/drivers/md/dm.c
+++ b/drivers/md/dm.c
@@ -809,6 +809,11 @@ static int __split_bio(struct mapped_device *md, struct bio *bio)
  * CRUD END
  *---------------------------------------------------------------*/
 
+static unsigned dm_metric(struct bio *bio)
+{
+	return 1;
+}
+
 /*
  * The request function that just remaps the bio built up by
  * dm_merge_bvec.
@@ -967,6 +972,7 @@ out:
 
 static struct block_device_operations dm_blk_dops;
 
+#define DEFAULT_THROTTLE_CAPACITY 1000
 /*
  * Allocate and initialise a blank device with a given minor.
  */
@@ -1009,6 +1015,11 @@ static struct mapped_device *alloc_dev(int minor)
 		goto bad1_free_minor;
 
 	md->queue->queuedata = md;
+	md->queue->metric = dm_metric;
+	/* A dm device constructor may change the throttle capacity */
+	atomic_set(&md->queue->available, md->queue->capacity = DEFAULT_THROTTLE_CAPACITY);
+	init_waitqueue_head(&md->queue->throttle_wait);
+
 	md->queue->backing_dev_info.congested_fn = dm_any_congested;
 	md->queue->backing_dev_info.congested_data = md;
 	blk_queue_make_request(md->queue, dm_request);
@@ -1571,6 +1582,7 @@ int dm_suspended(struct mapped_device *md)
 {
 	return test_bit(DMF_SUSPENDED, &md->flags);
 }
+EXPORT_SYMBOL_GPL(dm_suspended);
 
 int dm_noflush_suspending(struct dm_target *ti)
 {
diff --git a/fs/bio.c b/fs/bio.c
index d59ddbf..fc2a7fe 100644
--- a/fs/bio.c
+++ b/fs/bio.c
@@ -1009,6 +1009,13 @@ void bio_endio(struct bio *bio, int error)
 
 	if (bio->bi_end_io)
 		bio->bi_end_io(bio, error);
+
+	if (!bio->bi_size && bio->bi_queue) {
+		struct request_queue *q = bio->bi_queue;
+		atomic_add(bio->bi_max_vecs, &q->available);
+		bio->bi_queue = NULL; /* 0xdeadbeef? */
+		wake_up(&q->throttle_wait);
+	}
 }
 
 void bio_pair_release(struct bio_pair *bp)
diff --git a/include/linux/bio.h b/include/linux/bio.h
index 4da4413..638563f 100644
--- a/include/linux/bio.h
+++ b/include/linux/bio.h
@@ -111,6 +111,7 @@ struct bio {
 	bio_end_io_t		*bi_end_io;
 	atomic_t		bi_cnt;		/* pin count */
 
+	struct request_queue	*bi_queue;	/* for throttling */
 	void			*bi_private;
 
 	bio_destructor_t	*bi_destructor;	/* destructor */
diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
index d18ee67..045a560 100644
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -384,6 +384,10 @@ struct request_queue
 	struct work_struct	unplug_work;
 
 	struct backing_dev_info	backing_dev_info;
+	unsigned (*metric)(struct bio *bio);	/* (stub) bio throttle metric */
+	wait_queue_head_t	throttle_wait;
+	atomic_t		available;
+	unsigned		capacity;
 
 	/*
 	 * The queue owner gets to use this for whatever they like.
